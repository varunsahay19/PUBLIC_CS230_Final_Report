{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u71BpX3cLePr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uu1ybzyJlWW6"
      },
      "outputs": [],
      "source": [
        "# Importing Necessary Libraries\n",
        "import os\n",
        "os.environ['TF_ENABLE_ONEDNN_OPTS'] = \"0\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, Reshape, GRU, BatchNormalization, Softmax\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjCV1hedldiZ",
        "outputId": "73dc677e-2203-4591-c73e-51754d08dbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing helper function files\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/CS 230 Project')\n",
        "from utilLoss import *"
      ],
      "metadata": {
        "id": "NY1JI-gEpj5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the model to calculate the response spectrum\n",
        "responseModel = keras.models.load_model(\"/content/drive/MyDrive/CS 230 Project/responseModel.keras\")\n",
        "responseModel.trainable=False"
      ],
      "metadata": {
        "id": "Wvtw2V7wnI_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Custom loss model\n",
        "@register_keras_serializable()\n",
        "def responseLoss(y,yhat):\n",
        "    #MSE of predicted response spectra\n",
        "    ySpectrum=responseModel(y)\n",
        "    yhatSpectrum=responseModel(yhat)\n",
        "    spectrumLoss=tf.divide(tf.reduce_mean(tf.square(tf.subtract(ySpectrum,yhatSpectrum))),tf.reduce_mean(tf.square(ySpectrum)))\n",
        "\n",
        "    #Relative difference in Arias intensities\n",
        "    aly=tf.reduce_sum(tf.square(y))\n",
        "    alyhat=tf.reduce_sum(tf.square(yhat))\n",
        "    ariasLoss=tf.divide(tf.abs(tf.subtract(aly,alyhat)),aly)\n",
        "\n",
        "    #Direct MSE comparison of records, normalized\n",
        "    motionLoss=tf.divide(tf.reduce_mean(tf.square(tf.subtract(y,yhat))),tf.reduce_mean(tf.square(y)))\n",
        "\n",
        "    #Equally weight normalized losses\n",
        "    return tf.divide(tf.add(spectrumLoss,tf.add(ariasLoss,motionLoss)),3.0)"
      ],
      "metadata": {
        "id": "AUNoDS-ul4Tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the Preprocessed Data\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "xfilepath=\"/content/drive/MyDrive/CS 230 Project/4096_dataset/inputExpanded.csv\"\n",
        "ypath=\"/content/drive/MyDrive/CS 230 Project/4096_dataset/output.npy\"\n",
        "\n",
        "input_data= pd.read_csv(xfilepath)\n",
        "x= input_data.to_numpy()\n",
        "y=np.load(ypath)\n",
        "\n",
        "#Shuffle and split data into Train and Test Sets\n",
        "m=x.shape[0]\n",
        "testSplit=0.05\n",
        "shuffle=np.arange(m)\n",
        "np.random.shuffle(shuffle)\n",
        "x=x[shuffle,:]\n",
        "y=y[shuffle,:]\n",
        "index=int(np.floor(m*(1-testSplit)))\n",
        "xTrain=x[0:index,:]\n",
        "yTrain=y[0:index,:]\n",
        "xTest=x[index:,:]\n",
        "yTest=y[index:,:]"
      ],
      "metadata": {
        "id": "FZ2Ekv7zm8Kc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape, xTrain.shape, yTrain.shape, xTest.shape, yTest.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03kA5DB7r_hF",
        "outputId": "3e029668-f194-469c-9911-baf219962943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(53959, 93) (53959, 4096) (51261, 93) (51261, 4096) (2698, 93) (2698, 4096)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 1 Dense + 2 LSTM Layers + MSE Error -- Baseline\n",
        "\n",
        "# Constants\n",
        "INPUT_FEATURES = xTrain.shape[1]       # Number of input features\n",
        "SEQUENCE_LENGTH = yTrain.shape[1]      # Length of the output sequence\n",
        "HIDDEN_UNITS_1 = 1024        # LSTM layer 1 units\n",
        "HIDDEN_UNITS_2 = 1024        # LSTM layer 2 units\n",
        "DENSE_UNITS = 1024          # Dense layer units\n",
        "\n",
        "# Model Definition\n",
        "def build_model(input_features, sequence_length, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "    # Dense Layer\n",
        "    dense = Dense(dense_units, activation='relu')(input_layer)\n",
        "\n",
        "    # Reshape Layer (to prepare for LSTM input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # LSTM Layers\n",
        "    lstm_1 = LSTM(hidden_units_1, return_sequences=True)(reshape)\n",
        "    lstm_2 = LSTM(hidden_units_2, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(lstm_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = build_model(INPUT_FEATURES, SEQUENCE_LENGTH, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "# Train the model\n",
        "model.fit(xTrain, yTrain, epochs=1, batch_size=1024, validation_split=0.1)\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/CS 230 Project/lstm_model_1')\n",
        "\n",
        "# Load the model\n",
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('/content/drive/MyDrive/CS 230 Project/lstm_model_1')\n",
        "\n",
        "# Retrain the loaded model\n",
        "\n",
        "history = loaded_model.fit(xTrain, yTrain, epochs=10, batch_size=1024, validation_split=0.1)\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/CS 230 Project/lstm_model_1')"
      ],
      "metadata": {
        "id": "KWSEeUgF49Uv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 1 Dense + 2 LSTM Layers + MSE Error + LR = 0.01\n",
        "\n",
        "# Constants\n",
        "INPUT_FEATURES = xTrain.shape[1]       # Number of input features\n",
        "SEQUENCE_LENGTH = yTrain.shape[1]      # Length of the output sequence\n",
        "HIDDEN_UNITS_1 = 1024        # LSTM layer 1 units\n",
        "HIDDEN_UNITS_2 = 1024        # LSTM layer 2 units\n",
        "DENSE_UNITS = 1024          # Dense layer units\n",
        "\n",
        "# Model Definition\n",
        "def build_model(input_features, sequence_length, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "    # Dense Layer\n",
        "    dense = Dense(dense_units, activation='relu')(input_layer)\n",
        "\n",
        "    # Reshape Layer (to prepare for LSTM input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # LSTM Layers\n",
        "    lstm_1 = LSTM(hidden_units_1, return_sequences=True)(reshape)\n",
        "    lstm_2 = LSTM(hidden_units_2, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(lstm_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model_lrplus = build_model(INPUT_FEATURES, SEQUENCE_LENGTH, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model_lrplus.summary()\n",
        "# Train the model\n",
        "model_lrplus.fit(xTrain, yTrain, epochs=5, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "id": "Bd-YqrOH7xUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 1 Dense + 2 LSTM Layers + MSE Error + LR = 0.0001\n",
        "\n",
        "# Constants\n",
        "INPUT_FEATURES = xTrain.shape[1]       # Number of input features\n",
        "SEQUENCE_LENGTH = yTrain.shape[1]      # Length of the output sequence\n",
        "HIDDEN_UNITS_1 = 1024        # LSTM layer 1 units\n",
        "HIDDEN_UNITS_2 = 1024        # LSTM layer 2 units\n",
        "DENSE_UNITS = 1024          # Dense layer units\n",
        "\n",
        "# Model Definition\n",
        "def build_model(input_features, sequence_length, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "    # Dense Layer\n",
        "    dense = Dense(dense_units, activation='relu')(input_layer)\n",
        "\n",
        "    # Reshape Layer (to prepare for LSTM input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # LSTM Layers\n",
        "    lstm_1 = LSTM(hidden_units_1, return_sequences=True)(reshape)\n",
        "    lstm_2 = LSTM(hidden_units_2, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(lstm_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model_lrminus = build_model(INPUT_FEATURES, SEQUENCE_LENGTH, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model_lrminus.summary()\n",
        "# Train the model\n",
        "history_minus = model_lrminus.fit(xTrain, yTrain, epochs=5, batch_size=64, validation_split=0.1)\n",
        "# Save the model\n",
        "model_lrminus.save('/content/drive/MyDrive/Colab Notebooks/rnn_model_1024_lrminus.keras')"
      ],
      "metadata": {
        "id": "8kPmnIGv8W_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 2 Dense + 2 LSTM Layers + MSE Error + LR = 0.0001 (Extra Dense Layer)\n",
        "# Constants\n",
        "INPUT_FEATURES = xTrain.shape[1]       # Number of input features\n",
        "SEQUENCE_LENGTH = yTrain.shape[1]      # Length of the output sequence\n",
        "HIDDEN_UNITS_1 = 1024        # LSTM layer 1 units\n",
        "HIDDEN_UNITS_2 = 1024        # LSTM layer 2 units\n",
        "DENSE_UNITS = 1024          # Dense layer units\n",
        "\n",
        "# Model Definition\n",
        "def build_model(input_features, sequence_length, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "    # Dense Layer\n",
        "    dense = Dense(dense_units, activation='relu')(input_layer)\n",
        "\n",
        "    # Reshape Layer (to prepare for LSTM input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # LSTM Layers\n",
        "    lstm_1 = LSTM(hidden_units_1, return_sequences=True)(reshape)\n",
        "    lstm_2 = LSTM(hidden_units_2, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(lstm_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss='mse')\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model = build_model(INPUT_FEATURES, SEQUENCE_LENGTH, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model.summary()\n",
        "# Train the model\n",
        "model.fit(xTrain, yTrain, epochs=1, batch_size=64, validation_split=0.1)\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/CS 230 Project/lstm_model_2')\n",
        "\n",
        "# Load the model\n",
        "from tensorflow.keras.models import load_model\n",
        "loaded_model = load_model('/content/drive/MyDrive/CS 230 Project/lstm_model_2')\n",
        "\n",
        "# Retrain the loaded model\n",
        "loaded_model.fit(xTrain, yTrain, epochs=10, batch_size=64, validation_split=0.1)\n",
        "# Save the model\n",
        "model.save('/content/drive/MyDrive/CS 230 Project/lstm_model_2')"
      ],
      "metadata": {
        "id": "X2M2OrrS9Frv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 2 Dense + 2 LSTM Layers + + LR = 0.0001 +  Response Loss -- Custom Loss Function\n",
        "# Constants\n",
        "INPUT_FEATURES = xTrain.shape[1]       # Number of input features\n",
        "SEQUENCE_LENGTH = yTrain.shape[1]      # Length of the output sequence\n",
        "HIDDEN_UNITS_1 = 1024        # LSTM layer 1 units\n",
        "HIDDEN_UNITS_2 = 1024        # LSTM layer 2 units\n",
        "DENSE_UNITS = 1024          # Dense layer units\n",
        "DENSE_UNITS_1 = 256         # Extra Dense layer units\n",
        "\n",
        "# Model Definition\n",
        "def build_model(input_features, sequence_length, extradense_units, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "    # Dense Layer\n",
        "    dense = Dense(extradense_units, activation='relu')(input_layer)\n",
        "    dense = Dense(dense_units, activation='relu')(dense)\n",
        "\n",
        "    # Reshape Layer (to prepare for LSTM input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # LSTM Layers\n",
        "    lstm_1 = LSTM(hidden_units_1, return_sequences=True)(reshape)\n",
        "    lstm_2 = LSTM(hidden_units_2, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(lstm_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "    model.compile(optimizer=optimizer, loss=responseLoss, metrics=[responseLoss])\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "model_extradense = build_model(INPUT_FEATURES, SEQUENCE_LENGTH,DENSE_UNITS_1, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model_extradense.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "vf3Auw_w2HQg",
        "outputId": "58561880-9035-4754-a5ea-7714dfdc02ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m24,064\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │         \u001b[38;5;34m263,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (\u001b[38;5;33mReshape\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4096\u001b[0m)             │       \u001b[38;5;34m4,198,400\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,064</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,400</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,271,040\u001b[0m (81.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,271,040</span> (81.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,271,040\u001b[0m (81.14 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,271,040</span> (81.14 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_minus = model_extradense.fit(xTrain, yTrain, epochs=1, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebFDSWuw2q0U",
        "outputId": "2d597718-8319-48b5-9258-a3722411d559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m721/721\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1370s\u001b[0m 2s/step - loss: 0.9397 - response_loss: 0.9397 - val_loss: 0.8170 - val_response_loss: 0.8162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_extradense.save('/content/drive/MyDrive/CS 230 Project/rnn_model_1024_extradense_response_loss.keras')"
      ],
      "metadata": {
        "id": "nfqnv4vV5nlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 2 Dense + 2 LSTM Layers + Response Loss + Learning Rate = 0.0001 + Batch Normalization --- Final Model\n",
        "def build_model(input_features, sequence_length, extradense_units, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "    # Dense Layer + Batch Normalization\n",
        "    dense = Dense(extradense_units, activation='relu')(input_layer)\n",
        "    dense = BatchNormalization()(dense)  # Batch Normalization after first Dense\n",
        "    dense = Dense(dense_units, activation='relu')(dense)\n",
        "    dense = BatchNormalization()(dense)  # Batch Normalization after second Dense\n",
        "\n",
        "    # Reshape Layer (to prepare for LSTM input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # LSTM Layers\n",
        "    lstm_1 = LSTM(hidden_units_1, return_sequences=True)(reshape)\n",
        "    lstm_2 = LSTM(hidden_units_2, return_sequences=True)(lstm_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(lstm_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "    # Compile the model with custom loss function\n",
        "    model.compile(optimizer=optimizer, loss=responseLoss, metrics=[responseLoss])\n",
        "\n",
        "    return model\n",
        "model_1024_batch_norm=build_model(INPUT_FEATURES, SEQUENCE_LENGTH,DENSE_UNITS_1, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model_1024_batch_norm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "7-Xf64pgFMtx",
        "outputId": "1d0cda46-b2f2-4ee7-9a97-3b27636fced4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m24,064\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │         \u001b[38;5;34m263,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (\u001b[38;5;33mLSTM\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m8,392,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4096\u001b[0m)             │       \u001b[38;5;34m4,198,400\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,064</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">8,392,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,400</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,276,160\u001b[0m (81.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,276,160</span> (81.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,273,600\u001b[0m (81.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,273,600</span> (81.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_1024_batch_norm = model_1024_batch_norm.fit(xTrain, yTrain, epochs=1, batch_size=64, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErUkn5JRFOyx",
        "outputId": "27eb7912-f277-4c81-944f-d85d747517d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m721/721\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1362s\u001b[0m 2s/step - loss: 0.8392 - response_loss: 0.8392 - val_loss: 0.8040 - val_response_loss: 0.8033\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_1024_batch_norm.save('/content/drive/MyDrive/CS 230 Project/rnn_model_1024_batchnorm_response_loss.keras')"
      ],
      "metadata": {
        "id": "Ecuz2ahRFQgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and retrain the model\n",
        "model_1024_batch_norm = keras.models.load_model(\"/content/drive/MyDrive/CS 230 Project/rnn_model_1024_batchnorm_response_loss.keras\", custom_objects={'responseLoss': responseLoss})\n",
        "history_1024_batch_norm = model_1024_batch_norm.fit(xTrain, yTrain, epochs=2, batch_size=32, validation_split=0.1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d1iCNqwU7b6",
        "outputId": "f021844b-88a0-4596-ce8d-0c7712db2afb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1414s\u001b[0m 977ms/step - loss: 0.8312 - response_loss: 0.8312 - val_loss: 0.8274 - val_response_loss: 0.8279\n",
            "Epoch 2/2\n",
            "\u001b[1m1442/1442\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1451s\u001b[0m 970ms/step - loss: 0.8074 - response_loss: 0.8074 - val_loss: 0.8027 - val_response_loss: 0.8034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_1024_batch_norm.save('/content/drive/MyDrive/CS 230 Project/rnn_model_1024_batchnorm_response_loss.keras')"
      ],
      "metadata": {
        "id": "9mY4J8rqWvVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot to compare the generated and actual sequence\n",
        "%matplotlib inline\n",
        "\n",
        "# Number of examples to plot\n",
        "num_examples = 8\n",
        "\n",
        "# Create a figure and subplots\n",
        "fig, axes = plt.subplots(num_examples, 2, figsize=(12, 4 * num_examples))\n",
        "\n",
        "# Iterate through the examples\n",
        "for i in range(num_examples):\n",
        "    # Select a random example from the test set\n",
        "    example_index = np.random.randint(0, len(xTest))\n",
        "    test_input = np.reshape(xTest[example_index, :], (1, 93))\n",
        "    generated_sequence = model_1024_batch_norm.predict(test_input)\n",
        "\n",
        "    # Plot the generated sequence\n",
        "    axes[i, 0].plot(generated_sequence[0, 0, :], label='Generated Sequence', marker='o')\n",
        "    axes[i, 0].set_title(f\"Generated Sequence (Example {i+1})\")\n",
        "    axes[i, 0].set_xlabel(\"Time Step\")\n",
        "    axes[i, 0].set_ylabel(\"Value\")\n",
        "    axes[i, 0].legend()\n",
        "\n",
        "    # Plot the true sequence\n",
        "    axes[i, 1].plot(yTest[example_index, :], label='True Sequence', marker='x')\n",
        "    axes[i, 1].set_title(f\"True Sequence (Example {i+1})\")\n",
        "    axes[i, 1].set_xlabel(\"Time Step\")\n",
        "    axes[i, 1].set_ylabel(\"Value\")\n",
        "    axes[i, 1].legend()\n",
        "\n",
        "# Adjust spacing between subplots\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3DTiqNfDXr-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Desc: 2 Dense + 2 GRU Layers + Response Loss + Learning Rate = 0.0001 + Batch Normalization\n",
        "\n",
        "def build_model(input_features, sequence_length, extradense_units, dense_units, hidden_units_1, hidden_units_2):\n",
        "    # Input Layer\n",
        "    input_layer = Input(shape=(input_features,))\n",
        "\n",
        "\n",
        "    # Dense Layer + Batch Normalization\n",
        "    dense = Dense(extradense_units, activation='relu')(input_layer)\n",
        "    dense = BatchNormalization()(dense)  # Batch Normalization after the first Dense\n",
        "    dense = Dense(dense_units, activation='relu')(dense)\n",
        "    dense = BatchNormalization()(dense)  # Batch Normalization after the second Dense\n",
        "\n",
        "    # Reshape Layer (to prepare for GRU input)\n",
        "    reshape = Reshape((1, dense_units))(dense)\n",
        "\n",
        "    # GRU Layers\n",
        "    gru_1 = GRU(hidden_units_1, return_sequences=True)(reshape)\n",
        "    gru_2 = GRU(hidden_units_2, return_sequences=True)(gru_1)\n",
        "\n",
        "    # Output Layer (Dense with linear activation)\n",
        "    output_layer = Dense(sequence_length, activation='linear')(gru_2)\n",
        "\n",
        "    # Create Model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "    # Compile the model with custom loss function\n",
        "    model.compile(optimizer=optimizer, loss=responseLoss, metrics=[responseLoss])\n",
        "\n",
        "    return model\n",
        "\n",
        "model_1024_batch_norm_gru=build_model(INPUT_FEATURES, SEQUENCE_LENGTH,DENSE_UNITS_1, DENSE_UNITS, HIDDEN_UNITS_1, HIDDEN_UNITS_2)\n",
        "\n",
        "# Summary of the model\n",
        "model_1024_batch_norm_gru.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "eowa68DgHOQM",
        "outputId": "b725d0b9-7937-4185-8b74-5ecd79b11798"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m93\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m24,064\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │         \u001b[38;5;34m263,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)                │           \u001b[38;5;34m4,096\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_4 (\u001b[38;5;33mReshape\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m6,297,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_5 (\u001b[38;5;33mGRU\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │       \u001b[38;5;34m6,297,600\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m4096\u001b[0m)             │       \u001b[38;5;34m4,198,400\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">93</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,064</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │         <span style=\"color: #00af00; text-decoration-color: #00af00\">263,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_7                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ reshape_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,297,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ gru_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">6,297,600</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,400</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m17,085,952\u001b[0m (65.18 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,085,952</span> (65.18 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m17,083,392\u001b[0m (65.17 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17,083,392</span> (65.17 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history_1024_batch_norm = model_1024_batch_norm_gru.fit(xTrain, yTrain, epochs=1, batch_size=32, validation_split=0.1)"
      ],
      "metadata": {
        "id": "nxfhzf_1HoU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model_1024_batch_norm_gru.save('/content/drive/MyDrive/CS 230 Project/rnn_model_1024_batchnorm_response_loss_gru.keras')"
      ],
      "metadata": {
        "id": "1pczKj5xHq3s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}